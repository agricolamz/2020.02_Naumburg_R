[
["texts.html", "6 Text manipulations 6.1 read_lines() 6.2 gutenbergr 6.3 tidytext 6.4 udpipe 6.5 stylo", " 6 Text manipulations I will still use a lot of tidyverse: library(tidyverse) 6.1 read_lines() If you want to read text in R you can use the read_lines() function: romeo_i_julia &lt;- read_lines(&quot;https://raw.githubusercontent.com/agricolamz/2020.02_Naumburg_R/master/data/romeo_i_julia.txt&quot;) As a result you will get a vector with characters. It is easy to convert it to dataframe: tibble(text = romeo_i_julia) 6.2 gutenbergr The gutenbergr package is an API for a very old project Guttenberg, that is a library of over 60,000 free eBooks. library(gutenbergr) The most important part of this package is gutenberg_metadata dataset – that is a catalogue of everything in the Guttenberg library. str(gutenberg_metadata) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 51997 obs. of 8 variables: ## $ gutenberg_id : int 0 1 2 3 4 5 6 7 8 9 ... ## $ title : chr NA &quot;The Declaration of Independence of the United States of America&quot; &quot;The United States Bill of Rights\\r\\nThe Ten Original Amendments to the Constitution of the United States&quot; &quot;John F. Kennedy&#39;s Inaugural Address&quot; ... ## $ author : chr NA &quot;Jefferson, Thomas&quot; &quot;United States&quot; &quot;Kennedy, John F. (John Fitzgerald)&quot; ... ## $ gutenberg_author_id: int NA 1638 1 1666 3 1 4 NA 3 3 ... ## $ language : chr &quot;en&quot; &quot;en&quot; &quot;en&quot; &quot;en&quot; ... ## $ gutenberg_bookshelf: chr NA &quot;United States Law/American Revolutionary War/Politics&quot; &quot;American Revolutionary War/Politics/United States Law&quot; NA ... ## $ rights : chr &quot;Public domain in the USA.&quot; &quot;Public domain in the USA.&quot; &quot;Public domain in the USA.&quot; &quot;Public domain in the USA.&quot; ... ## $ has_text : logi TRUE TRUE TRUE TRUE TRUE TRUE ... ## - attr(*, &quot;date_updated&quot;)= Date, format: &quot;2016-05-05&quot; How many languages are presented in the Gutenberg library? gutenberg_metadata %&gt;% count(language, sort = TRUE) How many authors are availible? gutenberg_metadata %&gt;% count(author, sort = TRUE) How many Polish texts are availible? gutenberg_metadata %&gt;% filter(language == &quot;pl&quot;) %&gt;% count(author, sort = TRUE) Whose texts are the most numerous in German part of the Gutenberg library? Put his/her last name in the form. Lets have a look at the Polish part of Gutenberg library: gutenberg_metadata %&gt;% filter(author == &quot;Mickiewicz, Adam&quot;, language == &quot;pl&quot;) Lets download Adam Mickiewicz’s sonets: text &lt;- gutenberg_download(27081) ## Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest ## Using mirror http://aleph.gutenberg.org text It is possible to use multiple ids. Lets also download some poems by A. Mickiewicz (1798–1855), J. Kochanowski (1530–1584), Z. Krasinski (1812–1859), and A. Oppman (1867–1931): texts &lt;- gutenberg_download(c(27081, 27871, 28009, 27208)) ## Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest ## Using mirror http://aleph.gutenberg.org texts Be aware: texts could be stored with the wrong encoding; texts could be stored with normolised orthography (e. g. Kochanowski, look at rows 99 and 100); texts %&gt;% filter(gutenberg_id == 28009) there are a lot of empty characters; and probably a lot of other problems. I annotated those texts: texts &lt;- read_csv(&quot;https://raw.githubusercontent.com/agricolamz/2020.02_Naumburg_R/master/data/mickiewicz_kochanowski_krasinski_oppman.csv&quot;) ## Parsed with column specification: ## cols( ## gutenberg_id = col_double(), ## text = col_character(), ## title = col_character(), ## author = col_character() ## ) Now it is possible to remove some non-important lines: texts %&gt;% filter(title != &quot;remove&quot;) -&gt; texts texts Calculate how many rows per author do we have in our dataset. Who has the largest amount? 6.3 tidytext The tidytext (Silge and Robinson 2017) (this book is availible online) allows to work with texts in tidy ideology, hat make it esear to manipulate, summarize, and visualize the characteristics of text easily and integrate natural language processing tools (sentiment analysis, tf-idf metric, n-gram analysis, topic modeling etc.). library(tidytext) texts %&gt;% unnest_tokens(output = &quot;word&quot;, input = text) texts %&gt;% unnest_tokens(output = &quot;word&quot;, input = text) %&gt;% group_by(author) %&gt;% count(word, sort = TRUE) %&gt;% top_n(10) %&gt;% ggplot(aes(word, n))+ geom_col()+ coord_flip()+ facet_wrap(~author, scales = &quot;free&quot;) ## Selecting by n As you see the sorting is bad. Sorting within different facets is possible with reorder_within() function: texts %&gt;% unnest_tokens(output = &quot;word&quot;, input = text) %&gt;% group_by(author) %&gt;% count(word, sort = TRUE) %&gt;% top_n(10) %&gt;% ggplot(aes(reorder_within(x = word, by = n, within = author), n))+ geom_col()+ coord_flip()+ facet_wrap(~author, scales = &quot;free&quot;) ## Selecting by n In order to remove the author name you also need to add scale_x_reordered() layer to your ggplot: texts %&gt;% unnest_tokens(output = &quot;word&quot;, input = text) %&gt;% group_by(author) %&gt;% count(word, sort = TRUE) %&gt;% top_n(10) %&gt;% ggplot(aes(reorder_within(word, n, author), n))+ geom_col()+ scale_x_reordered()+ coord_flip()+ facet_wrap(~author, scales = &quot;free&quot;) ## Selecting by n Often in text analysis, it is useful to remove stop words. Stop words are frequent words that mostly contain grammatic information. I will use polish stopword list from this repository, but you can use any other. stopwords &lt;- read_lines(&quot;https://raw.githubusercontent.com/stopwords-iso/stopwords-pl/master/stopwords-pl.txt&quot;) stopwords ## [1] &quot;a&quot; &quot;aby&quot; &quot;ach&quot; &quot;acz&quot; &quot;aczkolwiek&quot; ## [6] &quot;aj&quot; &quot;albo&quot; &quot;ale&quot; &quot;ależ&quot; &quot;ani&quot; ## [11] &quot;aż&quot; &quot;bardziej&quot; &quot;bardzo&quot; &quot;bez&quot; &quot;bo&quot; ## [16] &quot;bowiem&quot; &quot;by&quot; &quot;byli&quot; &quot;bym&quot; &quot;bynajmniej&quot; ## [21] &quot;być&quot; &quot;był&quot; &quot;była&quot; &quot;było&quot; &quot;były&quot; ## [26] &quot;będzie&quot; &quot;będą&quot; &quot;cali&quot; &quot;cała&quot; &quot;cały&quot; ## [31] &quot;chce&quot; &quot;choć&quot; &quot;ci&quot; &quot;ciebie&quot; &quot;cię&quot; ## [36] &quot;co&quot; &quot;cokolwiek&quot; &quot;coraz&quot; &quot;coś&quot; &quot;czasami&quot; ## [41] &quot;czasem&quot; &quot;czemu&quot; &quot;czy&quot; &quot;czyli&quot; &quot;często&quot; ## [46] &quot;daleko&quot; &quot;dla&quot; &quot;dlaczego&quot; &quot;dlatego&quot; &quot;do&quot; ## [51] &quot;dobrze&quot; &quot;dokąd&quot; &quot;dość&quot; &quot;dr&quot; &quot;dużo&quot; ## [56] &quot;dwa&quot; &quot;dwaj&quot; &quot;dwie&quot; &quot;dwoje&quot; &quot;dzisiaj&quot; ## [61] &quot;dziś&quot; &quot;gdy&quot; &quot;gdyby&quot; &quot;gdyż&quot; &quot;gdzie&quot; ## [66] &quot;gdziekolwiek&quot; &quot;gdzieś&quot; &quot;go&quot; &quot;godz&quot; &quot;hab&quot; ## [71] &quot;i&quot; &quot;ich&quot; &quot;ii&quot; &quot;iii&quot; &quot;ile&quot; ## [76] &quot;im&quot; &quot;inna&quot; &quot;inne&quot; &quot;inny&quot; &quot;innych&quot; ## [81] &quot;inż&quot; &quot;iv&quot; &quot;ix&quot; &quot;iż&quot; &quot;ja&quot; ## [86] &quot;jak&quot; &quot;jakaś&quot; &quot;jakby&quot; &quot;jaki&quot; &quot;jakichś&quot; ## [91] &quot;jakie&quot; &quot;jakiś&quot; &quot;jakiż&quot; &quot;jakkolwiek&quot; &quot;jako&quot; ## [96] &quot;jakoś&quot; &quot;je&quot; &quot;jeden&quot; &quot;jedna&quot; &quot;jednak&quot; ## [101] &quot;jednakże&quot; &quot;jedno&quot; &quot;jednym&quot; &quot;jedynie&quot; &quot;jego&quot; ## [106] &quot;jej&quot; &quot;jemu&quot; &quot;jest&quot; &quot;jestem&quot; &quot;jeszcze&quot; ## [111] &quot;jeśli&quot; &quot;jeżeli&quot; &quot;już&quot; &quot;ją&quot; &quot;każdy&quot; ## [116] &quot;kiedy&quot; &quot;kierunku&quot; &quot;kilka&quot; &quot;kilku&quot; &quot;kimś&quot; ## [121] &quot;kto&quot; &quot;ktokolwiek&quot; &quot;ktoś&quot; &quot;która&quot; &quot;które&quot; ## [126] &quot;którego&quot; &quot;której&quot; &quot;który&quot; &quot;których&quot; &quot;którym&quot; ## [131] &quot;którzy&quot; &quot;ku&quot; &quot;lat&quot; &quot;lecz&quot; &quot;lub&quot; ## [136] &quot;ma&quot; &quot;mają&quot; &quot;mam&quot; &quot;mamy&quot; &quot;mało&quot; ## [141] &quot;mgr&quot; &quot;mi&quot; &quot;miał&quot; &quot;mimo&quot; &quot;między&quot; ## [146] &quot;mnie&quot; &quot;mną&quot; &quot;mogą&quot; &quot;moi&quot; &quot;moim&quot; ## [151] &quot;moja&quot; &quot;moje&quot; &quot;może&quot; &quot;możliwe&quot; &quot;można&quot; ## [156] &quot;mu&quot; &quot;musi&quot; &quot;my&quot; &quot;mój&quot; &quot;na&quot; ## [161] &quot;nad&quot; &quot;nam&quot; &quot;nami&quot; &quot;nas&quot; &quot;nasi&quot; ## [166] &quot;nasz&quot; &quot;nasza&quot; &quot;nasze&quot; &quot;naszego&quot; &quot;naszych&quot; ## [171] &quot;natomiast&quot; &quot;natychmiast&quot; &quot;nawet&quot; &quot;nic&quot; &quot;nich&quot; ## [176] &quot;nie&quot; &quot;niech&quot; &quot;niego&quot; &quot;niej&quot; &quot;niemu&quot; ## [181] &quot;nigdy&quot; &quot;nim&quot; &quot;nimi&quot; &quot;nią&quot; &quot;niż&quot; ## [186] &quot;no&quot; &quot;nowe&quot; &quot;np&quot; &quot;nr&quot; &quot;o&quot; ## [191] &quot;o.o.&quot; &quot;obok&quot; &quot;od&quot; &quot;ok&quot; &quot;około&quot; ## [196] &quot;on&quot; &quot;ona&quot; &quot;one&quot; &quot;oni&quot; &quot;ono&quot; ## [201] &quot;oraz&quot; &quot;oto&quot; &quot;owszem&quot; &quot;pan&quot; &quot;pana&quot; ## [206] &quot;pani&quot; &quot;pl&quot; &quot;po&quot; &quot;pod&quot; &quot;podczas&quot; ## [211] &quot;pomimo&quot; &quot;ponad&quot; &quot;ponieważ&quot; &quot;powinien&quot; &quot;powinna&quot; ## [216] &quot;powinni&quot; &quot;powinno&quot; &quot;poza&quot; &quot;prawie&quot; &quot;prof&quot; ## [221] &quot;przecież&quot; &quot;przed&quot; &quot;przede&quot; &quot;przedtem&quot; &quot;przez&quot; ## [226] &quot;przy&quot; &quot;raz&quot; &quot;razie&quot; &quot;roku&quot; &quot;również&quot; ## [231] &quot;sam&quot; &quot;sama&quot; &quot;się&quot; &quot;skąd&quot; &quot;sobie&quot; ## [236] &quot;sobą&quot; &quot;sposób&quot; &quot;swoje&quot; &quot;są&quot; &quot;ta&quot; ## [241] &quot;tak&quot; &quot;taka&quot; &quot;taki&quot; &quot;takich&quot; &quot;takie&quot; ## [246] &quot;także&quot; &quot;tam&quot; &quot;te&quot; &quot;tego&quot; &quot;tej&quot; ## [251] &quot;tel&quot; &quot;temu&quot; &quot;ten&quot; &quot;teraz&quot; &quot;też&quot; ## [256] &quot;to&quot; &quot;tobie&quot; &quot;tobą&quot; &quot;toteż&quot; &quot;trzeba&quot; ## [261] &quot;tu&quot; &quot;tutaj&quot; &quot;twoi&quot; &quot;twoim&quot; &quot;twoja&quot; ## [266] &quot;twoje&quot; &quot;twym&quot; &quot;twój&quot; &quot;ty&quot; &quot;tych&quot; ## [271] &quot;tylko&quot; &quot;tym&quot; &quot;tys&quot; &quot;tzw&quot; &quot;tę&quot; ## [276] &quot;u&quot; &quot;ul&quot; &quot;vi&quot; &quot;vii&quot; &quot;viii&quot; ## [281] &quot;vol&quot; &quot;w&quot; &quot;wam&quot; &quot;wami&quot; &quot;was&quot; ## [286] &quot;wasi&quot; &quot;wasz&quot; &quot;wasza&quot; &quot;wasze&quot; &quot;we&quot; ## [291] &quot;według&quot; &quot;wie&quot; &quot;wiele&quot; &quot;wielu&quot; &quot;więc&quot; ## [296] &quot;więcej&quot; &quot;wszyscy&quot; &quot;wszystkich&quot; &quot;wszystkie&quot; &quot;wszystkim&quot; ## [301] &quot;wszystko&quot; &quot;wtedy&quot; &quot;www&quot; &quot;wy&quot; &quot;właśnie&quot; ## [306] &quot;wśród&quot; &quot;xi&quot; &quot;xii&quot; &quot;xiii&quot; &quot;xiv&quot; ## [311] &quot;xv&quot; &quot;z&quot; &quot;za&quot; &quot;zapewne&quot; &quot;zawsze&quot; ## [316] &quot;zaś&quot; &quot;ze&quot; &quot;zeznowu&quot; &quot;znowu&quot; &quot;znów&quot; ## [321] &quot;został&quot; &quot;zł&quot; &quot;żaden&quot; &quot;żadna&quot; &quot;żadne&quot; ## [326] &quot;żadnych&quot; &quot;że&quot; &quot;żeby&quot; So now we are ready to remove stopwords using the antijoin() function: texts %&gt;% unnest_tokens(output = &quot;word&quot;, input = text) %&gt;% anti_join(tibble(word = stopwords)) %&gt;% # here is the stopwords removal group_by(author) %&gt;% count(word, sort = TRUE) %&gt;% top_n(10) %&gt;% ggplot(aes(reorder_within(word, n, author), n))+ geom_col()+ scale_x_reordered()+ coord_flip()+ facet_wrap(~author, scales = &quot;free&quot;) ## Joining, by = &quot;word&quot;Selecting by n It is also possible to analise bigrams texts %&gt;% unnest_tokens(output = &quot;bigrams&quot;, input = text, token = &quot;ngrams&quot;, n = 2) %&gt;% # separate into two seperate columns each part of bigram separate(bigrams, into = c(&quot;word_1&quot;, &quot;word_2&quot;), sep = &quot; &quot;) %&gt;% # filter out those that have stopwords anti_join(tibble(word_1 = stopwords)) %&gt;% anti_join(tibble(word_2 = stopwords)) %&gt;% # merge separate columns into one mutate(bigrams = str_c(word_1, word_2, sep = &quot; &quot;)) %&gt;% group_by(author) %&gt;% count(bigrams) %&gt;% top_n(4) %&gt;% ggplot(aes(reorder_within(bigrams, n, author), n))+ geom_col()+ scale_x_reordered()+ coord_flip()+ facet_wrap(~author, scales = &quot;free&quot;) ## Joining, by = &quot;word_1&quot;Joining, by = &quot;word_2&quot;Selecting by n Since our corpora for each outhor is really small we can’t see much (e. g. Mickiewicz no repetitions). If the text will be longer (e. g. long novels), you will be able to get the most important. Lets analyze “Tajemnicę Baskerville’ów”: tajemnica &lt;- gutenberg_download(34079) ## Determining mirror for Project Gutenberg from http://www.gutenberg.org/robot/harvest ## Using mirror http://aleph.gutenberg.org tajemnica %&gt;% unnest_tokens(output = &quot;bigrams&quot;, input = text, token = &quot;ngrams&quot;, n = 2) %&gt;% # separate into two seperate columns each part of bigram separate(bigrams, into = c(&quot;word_1&quot;, &quot;word_2&quot;), sep = &quot; &quot;) %&gt;% # filter out those that have stopwords anti_join(tibble(word_1 = stopwords)) %&gt;% anti_join(tibble(word_2 = stopwords)) %&gt;% # merge separate columns into one mutate(bigrams = str_c(word_1, word_2, sep = &quot; &quot;)) %&gt;% count(bigrams, sort = TRUE) %&gt;% top_n(20) %&gt;% ggplot(aes(fct_reorder(bigrams, n), n))+ geom_col()+ coord_flip() ## Joining, by = &quot;word_1&quot; ## Joining, by = &quot;word_2&quot;Selecting by n Analyse “Pan Tadeusz Czyli Ostatni Zajazd na Litwie” by A. Mickiewicz. What is the most frequent bigram in this text? 6.4 udpipe 6.5 stylo References "]
]
